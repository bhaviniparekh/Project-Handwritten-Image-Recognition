{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "import pydotplus\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_image(path):\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    Using OS library,read the directory path,directory name and files names of the directory.For each of the image files,\n",
    "    convert the image into pixel using the OpenCV library.\n",
    "    This function performs the following activity\n",
    "    Creates a dataframe where the number of columns = n x n (size of the image) and rows = number of images.\n",
    "    Creates a list of labels corresponding to the digit represented by each of the images. \n",
    "    \n",
    "    \n",
    "    Arguments:-\n",
    "    path =  The directory path which has the images to be converted to a corresponding dataframe \n",
    "            where each image is a vector of n*n\n",
    "            where the image is of the size n x n pixels\n",
    "    \n",
    "    Returns :-\n",
    "    df_images = Dataframe holding pixel values of each image\n",
    "    labels = The digit represented by each of the images. \n",
    "    \n",
    "    \n",
    "    '''\n",
    "                   \n",
    "    labels=[]                  #List to hold lable name for image ie digit the images belongs to.      \n",
    "    df_images=pd.DataFrame()   # Dataframe to hold the pixel values of every image\n",
    "    \n",
    "    for clustdir in os.listdir(path):\n",
    "        lab_name=int(clustdir)\n",
    "    \n",
    "        for file_name in os.listdir(os.path.join(path, clustdir)):\n",
    "        \n",
    "            img=cv2.imread(os.path.join(path,clustdir,file_name),0)\n",
    "            img_flat=img.flatten()                           #Flattern array to single dimension\n",
    "            img_flat=pd.Series(img_flat)\n",
    "            labels.append(lab_name) \n",
    "            df_images=df_images.append(img_flat,ignore_index=True)\n",
    "\n",
    "    \n",
    "    return df_images,pd.Series(labels)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_user_input():\n",
    "    '''\n",
    "    Ask the user to enter the directory path where the folders containing the images are present.\n",
    "    Keeps asking the user till the user enters a valid path \n",
    "    \n",
    "    '''\n",
    "    while True:    \n",
    "        dir_path=input('Enter directory path with ,do not enclose in quotes       :-  ')\n",
    "        if os.path.isdir(dir_path):\n",
    "            return vectorize_image(dir_path)\n",
    "        else:\n",
    "            print (\"Directory not exists. Re- Enter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(fitdata,transformdata,variance):\n",
    "    '''\n",
    "    The function creates a PCA object. The training data is fit on the object. The training data is transformed into the same object. Test\n",
    "    data is transformed on the same object on which training data was fit.\n",
    "    \n",
    "    Arguments:-\n",
    "    fitdata= Dataframe holding pixel values\n",
    "    transformdata :- Dataframe to transform the data to PCA data.\n",
    "    variance= percentage of variance needed to \n",
    "    \n",
    "    Returns :- Transformed data as per the percentage of variance \n",
    "    \n",
    "    ''' \n",
    "    pca = PCA(variance)\n",
    "    pca.fit(fitdata)\n",
    "    data_transformed=pca.transform(transformdata)\n",
    "    return pd.DataFrame(data_transformed)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cross_val(xdata,ydata,k_folds,clf):\n",
    "    \n",
    "    '''\n",
    "    Arguments:-\n",
    "    xdata :- pca transformed training data\n",
    "    ydata :- series holding label of images\n",
    "    k_folds :- number of n_split for StratifiedKFold\n",
    "    clf :- object of classifier\n",
    "    \n",
    "    Return :-  \n",
    "    scores :-Accuracy score\n",
    "    \n",
    "    Function uses StratifiedKFold to split data.\n",
    "    \n",
    "    Using the object of libraries of a given algorithm,training data is fit with ytrain lables to built a training model\n",
    "    \n",
    "    Using the same algorithm specific library object,test data is predicted and prediction for all the splits are stored in\n",
    "    a series against index matching to test index.\n",
    "    \n",
    "    Accuracy of predicted data is given back to respective algorithm calling function.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #Creating zeros series of final prediction\n",
    "    skFold=StratifiedKFold(n_splits=k_folds)\n",
    "    y_pred_final=pd.Series(np.zeros(ydata.shape[0]))  \n",
    "    for train_index,test_index in skFold.split(xdata,ydata):\n",
    "        \n",
    "        x_train,x_test=xdata.iloc[train_index],xdata.iloc[test_index]\n",
    "        y_train,y_test=ydata.iloc[train_index],ydata.iloc[test_index]\n",
    "        \n",
    "        y_pred,scores=classify_train_test(x_train,y_train,x_test,y_test,clf)\n",
    "        \n",
    "        #Put the predicted values as per the index locations of the test indices. \n",
    "        #At the end of all the folds we will have the predictions for the entire data set\n",
    "        for i in test_index:\n",
    "            y_pred_final[i]=y_pred[i]    \n",
    "    \n",
    "    scores=metrics.accuracy_score(ydata,y_pred_final)   \n",
    "    return scores\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_train_test(x_train,y_train,x_test,y_test,clf):\n",
    "    \n",
    "    '''\n",
    "    Based on the algorithm object, the respective fit method will fit the training data and Y train data. On the same object the\n",
    "    test data is predicted. The accuracy score is calculated using predicted data and Y test data.\n",
    "    \n",
    "    Argument :-\n",
    "    x_train- train data\n",
    "    y_train - y train data\n",
    "    x_test - x test data\n",
    "    y_test - y test data\n",
    "    clf - classifier algorithm object\n",
    "    \n",
    "    Return :- \n",
    "    ypred_final :- Predicted test data\n",
    "    score :-accuracy score of predicted data and Y test data.\n",
    "            \n",
    "    '''\n",
    "   \n",
    "    clf.fit(x_train,y_train)\n",
    "    ypred =clf.predict(x_test)\n",
    "    ypred_final=pd.Series(ypred,index=y_test.index)\n",
    "    \n",
    "    score=metrics.accuracy_score(y_test,ypred_final)  \n",
    "    \n",
    "    return ypred_final,score\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_validation_data(best_clf,pca_var):\n",
    "    \n",
    "\n",
    "    '''\n",
    "    This function is to get the accuracy score based on the best algorithm that we have obtained from GridSearch.The best \n",
    "    algorithm object and the best PCA variance is passed to this function.\n",
    "    \n",
    "    Argument :-\n",
    "    best_clf :- object of the best classifier\n",
    "    pca_var :- PCA variance\n",
    "    \n",
    "    Return :-\n",
    "    \n",
    "    scored :- Accuracy score report\n",
    "\n",
    "    '''\n",
    "  \n",
    "    \n",
    "        \n",
    "    #READING TRAINING DATA AND CONVERTTING TO PIXEL VALUES.\n",
    "    train_data,train_lst=dir_user_input()\n",
    "        \n",
    "    #TRANSFORM TRAIN DATA ON EXISTING PCA OBJECT\n",
    "    train_data_transformed=pca_transform(train_data,train_data,pca_var)\n",
    "        \n",
    "    #READING TEST DATA AND CONVERTTING TO PIXEL VALUES.\n",
    "    validation_data,validation_label=dir_user_input()\n",
    "                \n",
    "    #TRANSFORM TEST DATA ON EXISTING PCA OBJECT\n",
    "    test_pca_data=pca_transform(train_data,validation_data,pca_var)\n",
    "    \n",
    "    y_pred_class,scores=classify_train_test(train_data_transformed,train_lst,test_pca_data,validation_label,best_clf)\n",
    "    \n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (best_clf, metrics.classification_report(validation_label, y_pred_class)))\n",
    "    \n",
    "    return scores\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nb_algorithm(xdata,ydata,kfold,pca_var):\n",
    "    \n",
    "    '''\n",
    "    The function is for calculated the accuracy score for the Naive Bayes algorithm over different PCA variance. The data frame is\n",
    "    populated with accuracy score for different PCA variance.\n",
    "    \n",
    "    Argument :- \n",
    "    xdata :- pca transformed training data\n",
    "    ydata :- series holding label of images\n",
    "    kfold :- number of n_split for StratifiedKFold\n",
    "    pca_var :- PCA variance\n",
    "    \n",
    "    Return :-\n",
    "    nb_df :- Data Frame containing accuracy score for different PCA variance.\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    nb_df=pd.DataFrame(columns=['PCA','score'])  #Dataframe to hold the parameter values,score,PCA\n",
    "    nb_obj = GaussianNB()  \n",
    "    nb_acc_score = classify_cross_val(xdata,ydata,kfold,nb_obj)\n",
    "    nb_df.loc[len(nb_df)]=[comp,nb_acc_score]\n",
    "    \n",
    "    return nb_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree(xdata,ydata,kfold,pca_var,max_dep,min_spl,crit_value):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function is for executing the Decision Tree algorithm with permutation and combination of parameters and range of values.\n",
    "    The output of each combination is stored in the data frame. For further analysis, the data frame is exported to an excel file.\n",
    "    \n",
    "    Arguement :-\n",
    "    xdata :- pca transformed training data\n",
    "    ydata :- series holding label of images\n",
    "    kfold :- number of n_split for StratifiedKFold   \n",
    "    pca_var  :- PCA Variance\n",
    "    max_dep :- List holding a range of values for the max_depth parameter.\n",
    "    min_spl :- List holding a range of values for the min_sample_split parameter.\n",
    "    crit_value :- List holding a range of values for the criterion parameter.\n",
    "    \n",
    "    \n",
    "    Return :-\n",
    "    dt_df := Data frame\n",
    "    dt_obj :- Object of Decision Tree.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    dt_df=pd.DataFrame(columns=['PCA','max_depth','min_split','score','criterion'])  #Dataframe to hold the parameter values,score,PCA\n",
    "    \n",
    "    \n",
    "    for crit in crit_value:\n",
    "        for x in max_dep: \n",
    "            \n",
    "            for y in min_spl:\n",
    "                dt_obj=DecisionTreeClassifier(criterion=crit,max_depth=x,min_samples_split=y,random_state=42)\n",
    "                dt_score=classify_cross_val(xdata,ydata,kfold,dt_obj)\n",
    "                dt_df.loc[len(dt_df)]=[comp,x,y,dt_score,crit]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return dt_df,dt_obj\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_graph_display(dtobj,train_data,train_label):\n",
    "    \n",
    "    '''\n",
    "    Function is to view decision tree graphiclly ,save the graph in a pdf file.\n",
    "    \n",
    "    Argument :-\n",
    "    dtobj       - object of decision tree.\n",
    "    train_data  - train transformed data.\n",
    "    train_label -Series with actual digit number for every .\n",
    "    \n",
    "    '''\n",
    "      \n",
    "    os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "\n",
    "    dot_data = tree.export_graphviz(dtobj, out_file=None)  #convert data to graphically create the decision tree using the.\n",
    "      \n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)  # use the converted data to produce a graph.\n",
    "    graph.write_pdf(\"image17_graph.png\")             # write the graph to pdf format\n",
    "    Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_algorithm(xdata,ydata,kfold,comp,knn_lst):\n",
    "    \n",
    "    '''\n",
    "    The function is to create KNeightClassifer object for a range of knn values. Accuracy score for different knn values for a\n",
    "    given PCA variance is stored in a data frame for further analysis.\n",
    "    \n",
    "    \n",
    "    Argument :- \n",
    "    xdata :- pca transformed training data\n",
    "    ydata :- series holding label of images\n",
    "    kfold :- number of n_split for StratifiedKFold \n",
    "    comp :- PCA variance\n",
    "    knn_lst   :- Range of knn values\n",
    "    \n",
    "    Return :-\n",
    "    knn_df :- Data frame\n",
    "    \n",
    "    '''\n",
    "    accur_score={}\n",
    "    \n",
    "   \n",
    "    knn_df=pd.DataFrame(columns=['PCA','knn','score'])  #Dataframe to hold the parameter values,score,PCA\n",
    "    \n",
    "    for val in knn_lst:\n",
    "        knn=KNeighborsClassifier(n_neighbors=val,weights='uniform',metric='euclidean')\n",
    "        knn_score=classify_cross_val(xdata,ydata,kfold,knn)\n",
    "        knn_df.loc[len(knn_df)]=[comp,val,knn_score]\n",
    "    \n",
    "    return knn_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest(xdata,ydata,kfold,comp,est_lst,max_dep,min_spl,crit_value,):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function is for executing the RandomForest algorithm with permutation and combination of parameters and range of values.\n",
    "    The output of each combination is stored in the data frame. For further analysis, the data frame is exported to an excel file.\n",
    "    \n",
    "    Arguement :-\n",
    "    xdata :- pca transformed training data\n",
    "    ydata :- series holding label of images\n",
    "    kfold :- number of n_split for StratifiedKFold    \n",
    "    comp  :- PCA Variance\n",
    "    est_lst :- List holding a range of values for the n_estimator paramter\n",
    "    max_dep :- List holding a range of values for the max_depth parameter.\n",
    "    min_spl :- List holding a range of values for the min_sample_split parameter.\n",
    "    crit_value :- List holding a range of values for the criterion parameter.\n",
    "    \n",
    "    \n",
    "    Return :-\n",
    "    rf_df :- Data Frame.\n",
    "   \n",
    "    '''\n",
    "    rf_df=pd.DataFrame(columns=['PCA','n_estimator','max_depth','min_split','score','criterion'])  #Dataframe to hold the parameter values,score,PCA\n",
    "    for crit in crit_value:\n",
    "        for x in est_lst:  \n",
    "            for y in max_lst:\n",
    "                for z in min_samp_lst:\n",
    "            \n",
    "                    rfc_obj=RandomForestClassifier(criterion=crit,n_estimators=x,max_depth=y,min_samples_split=z,random_state=42)\n",
    "                    rfc_score=classify_cross_val(xdata,ydata,kfold,rfc_obj)\n",
    "                    rf_df.loc[len(rf_df)]=[comp,x,y,z,rfc_score,crit]\n",
    "  \n",
    "    return rf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel(dir_file):\n",
    "    \n",
    "    '''\n",
    "    The function is to create an object of excelwriter pointing to a excel file name and location passed as argument.\n",
    "    Argrument :-\n",
    "    dir_file :- directory path with file name\n",
    "    \n",
    "    Return :-\n",
    "    workbook :-Object of excel workbook\n",
    "    '''\n",
    "    \n",
    "    workbook=pd.ExcelWriter(dir_file, engine='openpyxl',mode='a')\n",
    "   \n",
    "\n",
    "    return workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_excel(df,writer,sheetname,path):\n",
    "    \n",
    "    '''\n",
    "    This function is to write the output to excel file.\n",
    "    \n",
    "    Argument :-\n",
    "    df- Dataset to export to the excel file\n",
    "    writer - object of the excel file\n",
    "    sheetname - Name of the sheet in the excel file.\n",
    "    path - Location of the excel file\n",
    "    \n",
    "    Return :-\n",
    "   write :- Object of excel file\n",
    "     \n",
    "    '''\n",
    "    lst1=['KNN','NB']\n",
    "    lst2=['DT','RF']\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        \n",
    "        wb=load_workbook(path)\n",
    "        if sheetname in wb.sheetnames:\n",
    "            if sheetname in lst1:\n",
    "                start_row=wb[sheetname].max_row\n",
    "                start_row=start_row+2\n",
    "                \n",
    "                df.to_excel(writer,sheet_name=sheetname,startrow=start_row,startcol=0,engine='openpyxl')\n",
    "                writer.close()\n",
    "                \n",
    "            elif sheetname in lst2:\n",
    "                print(sheetname)\n",
    "                start_col=wb[sheetname].max_column\n",
    "                start_col=start_col+2\n",
    "                \n",
    "                df.to_excel(writer,sheet_name=sheetname,startrow=0,startcol=start_col,engine='openpyxl')\n",
    "                writer.close()\n",
    "        else:\n",
    "            df.to_excel(writer,sheet_name=sheetname,startrow=0,startcol=0,engine='openpyxl')\n",
    "            writer.close()\n",
    "            \n",
    "                        \n",
    "    else:\n",
    "            \n",
    "        df.to_excel(writer,sheet_name=sheetname,startrow=0,startcol=0,engine='openpyxl')\n",
    "        writer.close()\n",
    "        \n",
    "    df.iloc[0:0]\n",
    "    df=df.dropna(axis=1,inplace=True)\n",
    "    \n",
    "    return writer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based GridSearch classfier giving the highest accuracy score,we now take the whole Training data ,use the PCA variance that was best with gridsearch,process,fit,tranform train data with pca object.Transform the test data on the same PCA object.Fit the pca transormed train data , train data label with classifier object defined with tuned parameter ,predict the test data on classifer object and find the final accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(xdata,ydata):\n",
    "    \n",
    "    '''\n",
    "    The function uses the GridSearch method to find the best model.\n",
    "    Multiple classifiers are passed with their respective parameters and a range of values.\n",
    "    \n",
    "    Argument :-\n",
    "    \n",
    "    xdata :- pca transformed training data\n",
    "    ydata :- series holding label of images\n",
    "    \n",
    "    Return \n",
    "    clf.best_score_ :-Best model score\n",
    "    clf.best_estimator_:-Best estimator object\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    k_range = list(range(3,10,2))\n",
    "    m_depth=list(range(10,14))\n",
    "    m_split=list(range(10,14))\n",
    "    est_range = list(range(100,250,50))\n",
    "   \n",
    "    \n",
    "    pipe= Pipeline([('classifier', KNeighborsClassifier())])\n",
    "\n",
    "\n",
    "    param_grid = [{\n",
    "        'classifier':[KNeighborsClassifier()],\n",
    "        'classifier__n_neighbors': k_range\n",
    "        },\n",
    "        {\n",
    "        'classifier':[DecisionTreeClassifier()],\n",
    "        'classifier__max_depth': m_depth,\n",
    "        'classifier__min_samples_split':m_split,\n",
    "        'classifier__criterion':['entropy','gini'],\n",
    "        'classifier__random_state':[42]   \n",
    "       },\n",
    "        {\n",
    "         'classifier':[RandomForestClassifier()],   \n",
    "         'classifier__n_estimators' :est_range,\n",
    "         'classifier__max_depth': m_depth,\n",
    "         'classifier__min_samples_split':m_split,\n",
    "         'classifier__criterion':['entropy','gini'],\n",
    "         'classifier__random_state':[42]   \n",
    "                   \n",
    "        },\n",
    "        {\n",
    "         'classifier':[GaussianNB()]   \n",
    "        \n",
    "        }] \n",
    "\n",
    "    clf=GridSearchCV(pipe,param_grid,cv=5)\n",
    "    clf.fit(xdata,ydata)\n",
    "    \n",
    "    return clf.best_score_,clf.best_estimator_\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User input for directory path holding images.\n",
    "\n",
    "train_pixel_data,train_label_lst=dir_user_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User input for PCA variance\n",
    "\n",
    "#comp= Variance of PCA\n",
    "\n",
    "comp=input('Enter the number of PCA variance       :- ')\n",
    "if '.' in comp:\n",
    "    comp=float(comp)\n",
    "    train_pca_data=pca_transform(train_pixel_data,train_pixel_data,comp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfold :- number of n_split for StratifiedKFold\n",
    "kfold=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the name and location to create an excel file\n",
    "excel_path ='D:\\\\excel_folder\\\\Supervised.xlsx'\n",
    "workbook = create_excel(excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Algorithm\n",
    "max_dep=[10,12,14]       #Range of max_depth\n",
    "min_samp_lst=[2,3]       #Range of min_sample_split\n",
    "criterion=['gini','entropy']\n",
    "\n",
    "df_dt,obj_dt=run_decision_tree(train_pca_data,train_label_lst,kfold,comp,max_dep,min_samp_lst,criterion)\n",
    "\n",
    "# Input from the user whether to export data frame data to an excel.Enter in smaller case without quotes\n",
    "\n",
    "flag=input('Enter yes to export dataframe data to an excel file else enter no       :-  ')\n",
    "\n",
    "if flag=='yes':\n",
    "    sheet='DT'\n",
    "    workbook=write_to_excel(df_dt,workbook,sheet,excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To view Decision Tree graphically in a file format\n",
    "dt_graph_display(obj_dt,train_pca_data,train_label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Algorithm\n",
    "\n",
    "est_lst=[100,150]  #Range of estimator values\n",
    "max_lst=[10,12]                       #Range of max_depth\n",
    "min_samp_lst=[3,10,15,17]             #Range of min_sample_split\n",
    "\n",
    "df_rf=run_random_forest(train_pca_data,train_label_lst,kfold,comp,est_lst,max_dep,min_samp_lst,criterion)\n",
    "\n",
    "# Input from the user whether to export data frame data to an excel.Enter in smaller case without quotes\n",
    "\n",
    "flag=input('Enter yes to export dataframe data to an excel file else enter no       :-  ')\n",
    "\n",
    "if flag=='yes':\n",
    "\n",
    "    sheet='RF'\n",
    "    workbook=write_to_excel(df_rf,workbook,sheet,excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Check the Accuracy score for Naive Baye's with Cross validation.\n",
    "\n",
    "df_nb=run_nb_algorithm(train_pca_data,train_label_lst,kfold,comp)\n",
    "\n",
    "# Input from the user whether to export data frame data to an excel.Enter in smaller case without quotes\n",
    "\n",
    "flag=input('Enter yes to export dataframe data to an excel file else enter no       :-  ')\n",
    "\n",
    "if flag=='yes':\n",
    "    sheet='NB'\n",
    "    workbook=write_to_excel(df_nb,workbook,sheet,excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Check the Accuracy score for k-nearest Neighbors with Cross validation.\n",
    "\n",
    "knn_list=list(range(3,10,2))\n",
    "df_knn=run_knn_algorithm(train_pca_data,train_label_lst,kfold,comp,knn_list)\n",
    "\n",
    "\n",
    "flag=input('Enter yes to export dataframe data to an excel file else enter no       :-  ')\n",
    "\n",
    "if flag=='yes':\n",
    "    sheet='KNN'\n",
    "    workbook=write_to_excel(df_knn,workbook,sheet,excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After individually executing the classier with permutation and combination of tuning parameter and range of PCA variance,now\n",
    "#use the grid search to find the best classifier.\n",
    "\n",
    "pca_var_dict={}\n",
    "#pca_var=[0.96,0.97,0.98,0.99]\n",
    "pca_var=[0.97]\n",
    "for var in pca_var:\n",
    "   \n",
    "    train_pca_data=pca_transform(train_pixel_data,train_pixel_data,var)\n",
    "    score,best_clf=get_best_model(train_pca_data,train_label_lst)\n",
    "    pca_var_dict.update({var:score})\n",
    "    \n",
    "max_v=max(zip(pca_var_dict.values(), pca_var_dict.keys())) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we take complete training data and convert to pixel values. Using PCA object and variance value we tranform the data to new set of component values. Same process is followed with test images.Training data is then fit on best classifier object. Test data is predicted over classifier object to get the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter directory path with ,do not enclose in quotes       :-  D:\\Project-Hand-Written-Charcter-reco\\training-images\n",
      "Enter directory path with ,do not enclose in quotes       :-  D:\\Project-Hand-Written-Charcter-reco\\test-images\n",
      "Classification report for classifier Pipeline(memory=None,\n",
      "     steps=[('classifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=11,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))]):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85        50\n",
      "           1       0.88      0.98      0.92        50\n",
      "           2       0.95      0.67      0.78        54\n",
      "           3       0.88      0.86      0.87        50\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       204\n",
      "   macro avg       0.87      0.86      0.86       204\n",
      "weighted avg       0.87      0.86      0.85       204\n",
      "\n",
      "\n",
      "0.8578431372549019\n"
     ]
    }
   ],
   "source": [
    "# By calling grid_search we get the object of the best classifier. This will then be passed to classify_validation_data to get the \n",
    "#accuracy score for best algorithm for this data set \n",
    "max_v=max(zip(pca_var_dict.values(), pca_var_dict.keys()))\n",
    "accuracy_score=classify_validation_data(best_clf,max_v[1])\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
